{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:13:02.303485",
     "start_time": "2016-07-10T09:13:02.299095"
    }
   },
   "source": [
    "In this notebook we use Lasagne to train a classifier for handwritten digit\n",
    "recognition (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:23:08.780661",
     "start_time": "2016-07-10T09:23:08.736120"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = 'device=gpu1, floatX=float32'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import matplotlib\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "from IPython.display import SVG\n",
    "import timeit\n",
    "\n",
    "import lasagne\n",
    "import lasagne.layers as ll\n",
    "\n",
    "# Display plots inline and change default figure size\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:15:51.019793",
     "start_time": "2016-07-10T09:15:45.047510"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:39:11.221446",
     "start_time": "2016-07-10T09:38:52.251645"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract & reshape data\n",
    "X_data, y_data = mnist['data'].reshape((-1,1,28,28)).astype(np.float32), mnist['target'].astype(np.int32)\n",
    "\n",
    "# shuffle data\n",
    "idx = np.arange(y_data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "X_data, y_data = X_data[idx], y_data[idx]\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test = X_data[:60000], X_data[60000:]\n",
    "y_train, y_test = y_data[:60000], y_data[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 1:** Draw a couple of sample from the training set and check that the\n",
    "labels are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 2**: Build a three-layer network (2 convolutions, 1 dense layer) in Lasagne.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:54:28.800523",
     "start_time": "2016-07-10T09:54:28.787914"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_var = T.ftensor4('x')\n",
    "target_var = T.ivector('y')\n",
    "\n",
    "net = {}\n",
    "\n",
    "net['input'] = ll.InputLayer((None,1,28,28), input_var)\n",
    "net['conv1'] = ll.Conv2DLayer(net['input'], num_filters=16, filter_size=7)\n",
    "net['pool1'] = ll.MaxPool2DLayer(net['conv1'], pool_size=2)\n",
    "net['conv2'] = ll.Conv2DLayer(net['pool1'], num_filters=32, filter_size=7)\n",
    "net['pool2'] = ll.MaxPool2DLayer(net['conv2'], pool_size=2)\n",
    "net['predict'] = ll.DenseLayer(net['pool2'], num_units=10, nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 2a: ** Define the cost function and compile a training and test function.\n",
    "\n",
    "**Excercise 2b: ** Plot the histogram over the prediction and check that you are not in a saturating regime (i.e. only 0 or 1).\n",
    "\n",
    "**Excercise 2c: ** If you are in a saturating regime, decrease the variance of the weights by adapting the initializiation.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:54:31.460220",
     "start_time": "2016-07-10T09:54:29.838151"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = ll.get_output(net['predict'])\n",
    "\n",
    "cost = lasagne.objectives.categorical_crossentropy(p, target_var).mean()\n",
    "acc  = lasagne.objectives.categorical_accuracy(p, target_var).mean()\n",
    "\n",
    "params = ll.get_all_params(net['predict'])\n",
    "updates = lasagne.updates.momentum(cost, params, learning_rate=0.01)\n",
    "\n",
    "# compile training function in the standard way\n",
    "train_fn = theano.function([input_var, target_var], [cost, acc], updates=updates)\n",
    "\n",
    "# compile separate test function that does not update parameters\n",
    "test_fn = theano.function([input_var, target_var], [cost, acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:54:32.033665",
     "start_time": "2016-07-10T09:54:31.462329"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAHVCAYAAABbmjfMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhhBmAABD/F9ylMWzEaifwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2db673b8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output predictions before adapting the initial weight distribution\n",
    "plt.hist(p.eval({input_var : X_test}).flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:54:34.331352",
     "start_time": "2016-07-10T09:54:34.319043"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adapt initialization\n",
    "net = {}\n",
    "\n",
    "gain = 0.3\n",
    "\n",
    "net['input'] = ll.InputLayer((None,1,28,28), input_var)\n",
    "net['conv1'] = ll.Conv2DLayer(net['input'], num_filters=16, filter_size=7, \n",
    "                              W=lasagne.init.GlorotUniform(gain=gain))\n",
    "net['pool1'] = ll.MaxPool2DLayer(net['conv1'], pool_size=2)\n",
    "net['conv2'] = ll.Conv2DLayer(net['pool1'], num_filters=32, filter_size=7, \n",
    "                              W=lasagne.init.GlorotUniform(gain=gain))\n",
    "net['pool2'] = ll.MaxPool2DLayer(net['conv2'], pool_size=2)\n",
    "net['predict'] = ll.DenseLayer(net['pool2'], num_units=10, nonlinearity=lasagne.nonlinearities.softmax, \n",
    "                               W=lasagne.init.GlorotUniform(gain=gain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:54:36.363975",
     "start_time": "2016-07-10T09:54:34.848887"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = ll.get_output(net['predict'])\n",
    "\n",
    "cost = lasagne.objectives.categorical_crossentropy(p, target_var).mean()\n",
    "acc  = lasagne.objectives.categorical_accuracy(p, target_var).mean()\n",
    "\n",
    "params = ll.get_all_params(net['predict'])\n",
    "updates = lasagne.updates.momentum(cost, params, learning_rate=0.001)\n",
    "\n",
    "# compile training function in the standard way\n",
    "train_fn = theano.function([input_var, target_var], [cost, acc], updates=updates)\n",
    "\n",
    "# compile separate test function that does not update parameters\n",
    "test_fn = theano.function([input_var, target_var], [cost, acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:54:37.151733",
     "start_time": "2016-07-10T09:54:36.367114"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAHVCAYAAABbmjfMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nANCEMAMAaEKYAQA0IcwAAJoQZgAATfwf8hlp1MOK/ngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2dbc44a690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output predictions before adapting the initial weight distribution\n",
    "plt.hist(p.eval({input_var : X_test}).flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 3:** Train the network on **mini-batches** of size 100.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T09:57:26.371661",
     "start_time": "2016-07-10T09:57:11.353749"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Training performance:  0.000103646208147 1.0\n",
      "Validation performance:  0.0613833069801 0.9909\n",
      "Epoch  1\n",
      "Training performance:  8.48476765818e-05 1.0\n",
      "Validation performance:  0.0617880858481 0.9907\n",
      "Epoch  2\n",
      "Training performance:  7.49056907838e-05 1.0\n",
      "Validation performance:  0.062119923532 0.9906\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-40a2412ac3c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# iterate over batch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbidx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbidx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbidx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbidx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbidx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mepoch_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mepoch_acc\u001b[0m  \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    epoch_cost, epoch_acc, k = 0, 0, 0\n",
    "    # iterate over batch_index\n",
    "    for bidx in range(60000/100):\n",
    "        cost, acc = train_fn(X_train[bidx*100:(bidx+1)*100], y_train[bidx*100:(bidx+1)*100])\n",
    "        epoch_cost += cost\n",
    "        epoch_acc  += acc\n",
    "        k += 1\n",
    "        \n",
    "    epoch_cost /= k\n",
    "    epoch_acc  /= k\n",
    "    \n",
    "    print \"Epoch \", str(epoch)\n",
    "    print \"Training performance: \", epoch_cost, epoch_acc\n",
    "    \n",
    "    test_cost, test_acc = test_fn(X_test, y_test)\n",
    "    print \"Validation performance: \", test_cost, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 3**: Play around with learning rates, update rules (e.g. Adam), regularizations (e.g. dropout) \n",
    "and different architectures. What is the best test performance you can get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your own Lasagne Layer\n",
    "\n",
    "A big advantage of Lasagne is that you can easily write your own Lasagne Layers.\n",
    "\n",
    "**Excercise 3**: Go through the [quick tutorial](http://lasagne.readthedocs.io/en/latest/user/custom_layers.html) in the Lasagne documentation on how to write your own Layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the definition of the dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T10:02:12.333413",
     "start_time": "2016-07-10T10:02:12.297443"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers.base import Layer\n",
    "from lasagne import init, nonlinearities\n",
    "\n",
    "class DenseLayer(Layer):\n",
    "    \"\"\"\n",
    "    lasagne.layers.DenseLayer(incoming, num_units,\n",
    "    W=lasagne.init.GlorotUniform(), b=lasagne.init.Constant(0.),\n",
    "    nonlinearity=lasagne.nonlinearities.rectify, **kwargs)\n",
    "    A fully connected layer.\n",
    "    Parameters\n",
    "    ----------\n",
    "    incoming : a :class:`Layer` instance or a tuple\n",
    "        The layer feeding into this layer, or the expected input shape\n",
    "    num_units : int\n",
    "        The number of units of the layer\n",
    "    W : Theano shared variable, expression, numpy array or callable\n",
    "        Initial value, expression or initializer for the weights.\n",
    "        These should be a matrix with shape ``(num_inputs, num_units)``.\n",
    "        See :func:`lasagne.utils.create_param` for more information.\n",
    "    b : Theano shared variable, expression, numpy array, callable or ``None``\n",
    "        Initial value, expression or initializer for the biases. If set to\n",
    "        ``None``, the layer will have no biases. Otherwise, biases should be\n",
    "        a 1D array with shape ``(num_units,)``.\n",
    "        See :func:`lasagne.utils.create_param` for more information.\n",
    "    nonlinearity : callable or None\n",
    "        The nonlinearity that is applied to the layer activations. If None\n",
    "        is provided, the layer will be linear.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from lasagne.layers import InputLayer, DenseLayer\n",
    "    >>> l_in = InputLayer((100, 20))\n",
    "    >>> l1 = DenseLayer(l_in, num_units=50)\n",
    "    Notes\n",
    "    -----\n",
    "    If the input to this layer has more than two axes, it will flatten the\n",
    "    trailing axes. This is useful for when a dense layer follows a\n",
    "    convolutional layer, for example. It is not necessary to insert a\n",
    "    :class:`FlattenLayer` in this case.\n",
    "    \"\"\"\n",
    "    def __init__(self, incoming, num_units, W=init.GlorotUniform(),\n",
    "                 b=init.Constant(0.), nonlinearity=nonlinearities.rectify,\n",
    "                 **kwargs):\n",
    "        super(DenseLayer, self).__init__(incoming, **kwargs)\n",
    "        self.nonlinearity = (nonlinearities.identity if nonlinearity is None\n",
    "                             else nonlinearity)\n",
    "\n",
    "        self.num_units = num_units\n",
    "\n",
    "        num_inputs = int(np.prod(self.input_shape[1:]))\n",
    "\n",
    "        self.W = self.add_param(W, (num_inputs, num_units), name=\"W\")\n",
    "        if b is None:\n",
    "            self.b = None\n",
    "        else:\n",
    "            self.b = self.add_param(b, (num_units,), name=\"b\",\n",
    "                                    regularizable=False)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.num_units)\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        if input.ndim > 2:\n",
    "            # if the input has more than two dimensions, flatten it into a\n",
    "            # batch of feature vectors.\n",
    "            input = input.flatten(2)\n",
    "\n",
    "        activation = T.dot(input, self.W)\n",
    "        if self.b is not None:\n",
    "            activation = activation + self.b.dimshuffle('x', 0)\n",
    "        return self.nonlinearity(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 4a:** Implement a layer that keeps the length of each feature vector (i.e. the input weights to each unit)\n",
    "constant at 1.\n",
    "\n",
    "**Bonus Excercise:** Implement the length of each feature vector as its own parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T10:05:06.040187",
     "start_time": "2016-07-10T10:05:05.984911"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NormedDenseLayer(Layer):\n",
    "    \"\"\"\n",
    "    lasagne.layers.DenseLayer(incoming, num_units,\n",
    "    W=lasagne.init.GlorotUniform(), b=lasagne.init.Constant(0.),\n",
    "    nonlinearity=lasagne.nonlinearities.rectify, **kwargs)\n",
    "    A fully connected layer.\n",
    "    Parameters\n",
    "    ----------\n",
    "    incoming : a :class:`Layer` instance or a tuple\n",
    "        The layer feeding into this layer, or the expected input shape\n",
    "    num_units : int\n",
    "        The number of units of the layer\n",
    "    W : Theano shared variable, expression, numpy array or callable\n",
    "        Initial value, expression or initializer for the weights.\n",
    "        These should be a matrix with shape ``(num_inputs, num_units)``.\n",
    "        See :func:`lasagne.utils.create_param` for more information.\n",
    "    b : Theano shared variable, expression, numpy array, callable or ``None``\n",
    "        Initial value, expression or initializer for the biases. If set to\n",
    "        ``None``, the layer will have no biases. Otherwise, biases should be\n",
    "        a 1D array with shape ``(num_units,)``.\n",
    "        See :func:`lasagne.utils.create_param` for more information.\n",
    "    nonlinearity : callable or None\n",
    "        The nonlinearity that is applied to the layer activations. If None\n",
    "        is provided, the layer will be linear.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from lasagne.layers import InputLayer, DenseLayer\n",
    "    >>> l_in = InputLayer((100, 20))\n",
    "    >>> l1 = DenseLayer(l_in, num_units=50)\n",
    "    Notes\n",
    "    -----\n",
    "    If the input to this layer has more than two axes, it will flatten the\n",
    "    trailing axes. This is useful for when a dense layer follows a\n",
    "    convolutional layer, for example. It is not necessary to insert a\n",
    "    :class:`FlattenLayer` in this case.\n",
    "    \"\"\"\n",
    "    def __init__(self, incoming, num_units, W=init.GlorotUniform(),\n",
    "                 b=init.Constant(0.), nonlinearity=nonlinearities.rectify,\n",
    "                 **kwargs):\n",
    "        super(NormedDenseLayer, self).__init__(incoming, **kwargs)\n",
    "        self.nonlinearity = (nonlinearities.identity if nonlinearity is None\n",
    "                             else nonlinearity)\n",
    "\n",
    "        self.num_units = num_units\n",
    "\n",
    "        num_inputs = int(np.prod(self.input_shape[1:]))\n",
    "\n",
    "        self.W = self.add_param(W, (num_inputs, num_units), name=\"W\")\n",
    "        if b is None:\n",
    "            self.b = None\n",
    "        else:\n",
    "            self.b = self.add_param(b, (num_units,), name=\"b\",\n",
    "                                    regularizable=False)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.num_units)\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        if input.ndim > 2:\n",
    "            # if the input has more than two dimensions, flatten it into a\n",
    "            # batch of feature vectors.\n",
    "            input = input.flatten(2)\n",
    "\n",
    "        W = self.W / T.sqrt((self.W**2).sum(1)).dimshuffle([0, 'x'])\n",
    "        activation = T.dot(input, W)\n",
    "        if self.b is not None:\n",
    "            activation = activation + self.b.dimshuffle('x', 0)\n",
    "        return self.nonlinearity(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T10:05:48.908604",
     "start_time": "2016-07-10T10:05:48.897309"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "# adapt initialization\n",
    "net = {}\n",
    "\n",
    "gain = 0.3\n",
    "\n",
    "net['input'] = ll.InputLayer((None,1,28,28), input_var)\n",
    "net['conv1'] = ll.Conv2DLayer(net['input'], num_filters=16, filter_size=7, \n",
    "                              W=lasagne.init.GlorotUniform(gain=gain))\n",
    "net['pool1'] = ll.MaxPool2DLayer(net['conv1'], pool_size=2)\n",
    "net['conv2'] = ll.Conv2DLayer(net['pool1'], num_filters=32, filter_size=7, \n",
    "                              W=lasagne.init.GlorotUniform(gain=gain))\n",
    "net['pool2'] = ll.MaxPool2DLayer(net['conv2'], pool_size=2)\n",
    "net['predict'] = NormedDenseLayer(net['pool2'], num_units=10, nonlinearity=lasagne.nonlinearities.softmax, \n",
    "                               W=lasagne.init.GlorotUniform(gain=gain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T10:06:50.157900",
     "start_time": "2016-07-10T10:05:59.760658"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = ll.get_output(net['predict'])\n",
    "\n",
    "cost = lasagne.objectives.categorical_crossentropy(p, target_var).mean()\n",
    "acc  = lasagne.objectives.categorical_accuracy(p, target_var).mean()\n",
    "\n",
    "params = ll.get_all_params(net['predict'])\n",
    "updates = lasagne.updates.momentum(cost, params, learning_rate=0.001)\n",
    "\n",
    "# compile training function in the standard way\n",
    "train_fn = theano.function([input_var, target_var], [cost, acc], updates=updates)\n",
    "\n",
    "# compile separate test function that does not update parameters\n",
    "test_fn = theano.function([input_var, target_var], [cost, acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-10T10:08:35.988041",
     "start_time": "2016-07-10T10:06:50.159966"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Training performance:  0.614844428829 0.851983333333\n",
      "Validation performance:  0.240344464779 0.9281\n",
      "Epoch  1\n",
      "Training performance:  0.217815038146 0.937683333333\n",
      "Validation performance:  0.212990552187 0.9479\n",
      "Epoch  2\n",
      "Training performance:  0.179053503269 0.949466666667\n",
      "Validation performance:  0.187772169709 0.95\n",
      "Epoch  3\n",
      "Training performance:  0.160185345652 0.954616666667\n",
      "Validation performance:  0.14772477746 0.9602\n",
      "Epoch  4\n",
      "Training performance:  0.151376889832 0.956716666667\n",
      "Validation performance:  0.171485871077 0.9545\n",
      "Epoch  5\n",
      "Training performance:  0.142938228104 0.958966666667\n",
      "Validation performance:  0.176893934608 0.9572\n",
      "Epoch  6\n",
      "Training performance:  0.144608001243 0.960066666667\n",
      "Validation performance:  0.14722533524 0.9644\n",
      "Epoch  7\n",
      "Training performance:  0.14260520929 0.960366666667\n",
      "Validation performance:  0.148414209485 0.9639\n",
      "Epoch  8\n",
      "Training performance:  0.133126702275 0.963016666667\n",
      "Validation performance:  0.17935217917 0.9591\n",
      "Epoch  9\n",
      "Training performance:  0.124563701147 0.96565\n",
      "Validation performance:  0.160380229354 0.9645\n",
      "Epoch  10\n",
      "Training performance:  0.120537884072 0.96555\n",
      "Validation performance:  0.169511005282 0.9635\n",
      "Epoch  11\n",
      "Training performance:  0.122136352131 0.965883333333\n",
      "Validation performance:  0.165368929505 0.9617\n",
      "Epoch  12\n",
      "Training performance:  0.115808544795 0.96735\n",
      "Validation performance:  0.15153439343 0.9617\n",
      "Epoch  13\n",
      "Training performance:  0.116877553804 0.967366666667\n",
      "Validation performance:  0.159283772111 0.9643\n",
      "Epoch  14\n",
      "Training performance:  0.113376838304 0.9682\n",
      "Validation performance:  0.171649485826 0.9624\n",
      "Epoch  15\n",
      "Training performance:  0.110256526302 0.96955\n",
      "Validation performance:  0.132441923022 0.9672\n",
      "Epoch  16\n",
      "Training performance:  0.106707028413 0.969933333333\n",
      "Validation performance:  0.159649163485 0.965\n",
      "Epoch  17\n",
      "Training performance:  0.106368551903 0.9704\n",
      "Validation performance:  0.160732746124 0.9625\n",
      "Epoch  18\n",
      "Training performance:  0.103221871064 0.97075\n",
      "Validation performance:  0.139535844326 0.9672\n",
      "Epoch  19\n",
      "Training performance:  0.10400456264 0.970816666667\n",
      "Validation performance:  0.131938576698 0.9657\n",
      "Epoch  20\n",
      "Training performance:  0.103157015207 0.971016666667\n",
      "Validation performance:  0.169505000114 0.9651\n",
      "Epoch  21\n",
      "Training performance:  0.0986809612246 0.972216666667\n",
      "Validation performance:  0.175531536341 0.9623\n",
      "Epoch  22\n",
      "Training performance:  0.101370206613 0.971466666667\n",
      "Validation performance:  0.165171951056 0.9663\n",
      "Epoch  23\n",
      "Training performance:  0.106208840562 0.970883333333\n",
      "Validation performance:  0.166067242622 0.9635\n",
      "Epoch  24\n",
      "Training performance:  0.103557007309 0.97125\n",
      "Validation performance:  0.167204901576 0.9635\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    epoch_cost, epoch_acc, k = 0, 0, 0\n",
    "    # iterate over batch_index\n",
    "    for bidx in range(60000/100):\n",
    "        cost, acc = train_fn(X_train[bidx*100:(bidx+1)*100], y_train[bidx*100:(bidx+1)*100])\n",
    "        epoch_cost += cost\n",
    "        epoch_acc  += acc\n",
    "        k += 1\n",
    "        \n",
    "    epoch_cost /= k\n",
    "    epoch_acc  /= k\n",
    "    \n",
    "    print \"Epoch \", str(epoch)\n",
    "    print \"Training performance: \", epoch_cost, epoch_acc\n",
    "    \n",
    "    test_cost, test_acc = test_fn(X_test, y_test)\n",
    "    print \"Validation performance: \", test_cost, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
